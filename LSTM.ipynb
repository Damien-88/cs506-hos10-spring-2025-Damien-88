{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5116faac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "import numpy as np \n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0067b70",
   "metadata": {},
   "source": [
    "Load Book with UTF-8 Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "288cc002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the project gutenberg ebook of trading with mexico\n",
      "    \n",
      "this ebook is for the use of anyone anywhere in the united states and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever. you may copy it, give it away or re-use it under the terms\n",
      "of the project gutenberg license included with this ebook or online\n",
      "at www.gutenberg.org. if you are not located in the united states,\n",
      "you will have to check the laws of the country where you are located\n",
      "before using this ebook.\n",
      "\n",
      "title: trading with mexico\n",
      "\n",
      "author: wallace thompson\n",
      "\n",
      "release date: february 26, 2025 [ebook #75469]\n",
      "\n",
      "language: english\n",
      "\n",
      "original publication: new york: dodd, mead and company, 1921\n",
      "\n",
      "credits: the online distributed proofreading team at https://www.pgdp.net (this file was produced from images generously made available by the internet archive)\n",
      "\n",
      "\n",
      "*** start of the project gutenberg ebook trading with mexico ***\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                              trading with\n",
      "                                 mexico\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename = \"Trading with Mexico.txt\"\n",
    "raw_text = open(filename, \"r\", encoding = \"utf-8\").read()\n",
    "raw_text = raw_text.lower()\n",
    "print(raw_text[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9dda25",
   "metadata": {},
   "source": [
    "Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4aab91e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = \"\".join(c for c in raw_text if not c.isdigit())\n",
    "chars = sorted(list(set(raw_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22297462",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c5efc9",
   "metadata": {},
   "source": [
    "Review Unique Chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e958393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters in the text; corpus length:  387019\n",
      "Total Vocab:  63\n"
     ]
    }
   ],
   "source": [
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters in the text; corpus length: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc34aa4b",
   "metadata": {},
   "source": [
    "Set Sequence and Skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbdeb404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 38696\n"
     ]
    }
   ],
   "source": [
    "seq_length = 60\n",
    "step = 10\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, n_chars - seq_length, step):\n",
    "    sentences.append(raw_text[i: i + seq_length])\n",
    "    next_chars.append(raw_text[i + seq_length])\n",
    "\n",
    "n_patterns = len(sentences)\n",
    "print(\"Number of sequences:\", n_patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e9a58c",
   "metadata": {},
   "source": [
    "Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "036efdf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38696, 60, 63)\n",
      "(38696, 63)\n",
      "[[False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False  True False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False]\n",
      " [False  True False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False  True False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False  True False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "   True False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False  True False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "   True False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False  True False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False  True False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False]\n",
      " [False  True False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False]]\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros((len(sentences), seq_length, n_vocab), dtype = np.bool_)\n",
    "y = np.zeros((len(sentences), n_vocab), dtype = np.bool_)\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_to_int[char]] = 1\n",
    "    y[i, char_to_int[next_chars[i]]] = 1\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(y[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a346e7",
   "metadata": {},
   "source": [
    "Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "930f1093",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nikolai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,304</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,127</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m98,304\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m)             │         \u001b[38;5;34m8,127\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">106,431</span> (415.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m106,431\u001b[0m (415.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">106,431</span> (415.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m106,431\u001b[0m (415.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape = (seq_length, n_vocab)))\n",
    "model.add(Dense(n_vocab, activation = \"softmax\"))\n",
    "\n",
    "optimizer = RMSprop(learning_rate = 0.01)\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3eaeaa",
   "metadata": {},
   "source": [
    "Define Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c96eb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "filepath = \"saved_weights-{epoch:02d}-{loss:.4f}.keras\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor = \"loss\", verbose = 1, save_best_only = True, mode = \"min\")\n",
    "\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0991e82e",
   "metadata": {},
   "source": [
    "Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2899a6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 2.7828\n",
      "Epoch 1: loss improved from inf to 2.47948, saving model to saved_weights-01-2.4795.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 43ms/step - loss: 2.7818\n",
      "Epoch 2/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 2.0758\n",
      "Epoch 2: loss improved from 2.47948 to 2.02207, saving model to saved_weights-02-2.0221.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - loss: 2.0755\n",
      "Epoch 3/50\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 1.8519\n",
      "Epoch 3: loss improved from 2.02207 to 1.83411, saving model to saved_weights-03-1.8341.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - loss: 1.8519\n",
      "Epoch 4/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 1.7111\n",
      "Epoch 4: loss improved from 1.83411 to 1.70204, saving model to saved_weights-04-1.7020.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - loss: 1.7110\n",
      "Epoch 5/50\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 1.5839\n",
      "Epoch 5: loss improved from 1.70204 to 1.59743, saving model to saved_weights-05-1.5974.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 42ms/step - loss: 1.5840\n",
      "Epoch 6/50\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 1.4895\n",
      "Epoch 6: loss improved from 1.59743 to 1.50674, saving model to saved_weights-06-1.5067.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - loss: 1.4896\n",
      "Epoch 7/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 1.4087\n",
      "Epoch 7: loss improved from 1.50674 to 1.42636, saving model to saved_weights-07-1.4264.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - loss: 1.4089\n",
      "Epoch 8/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 1.3274\n",
      "Epoch 8: loss improved from 1.42636 to 1.35950, saving model to saved_weights-08-1.3595.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - loss: 1.3276\n",
      "Epoch 9/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 1.2726\n",
      "Epoch 9: loss improved from 1.35950 to 1.30185, saving model to saved_weights-09-1.3019.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 42ms/step - loss: 1.2728\n",
      "Epoch 10/50\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 1.2064\n",
      "Epoch 10: loss improved from 1.30185 to 1.25095, saving model to saved_weights-10-1.2509.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - loss: 1.2066\n",
      "Epoch 11/50\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 1.1673\n",
      "Epoch 11: loss improved from 1.25095 to 1.20818, saving model to saved_weights-11-1.2082.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - loss: 1.1674\n",
      "Epoch 12/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.1286\n",
      "Epoch 12: loss improved from 1.20818 to 1.17154, saving model to saved_weights-12-1.1715.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - loss: 1.1289\n",
      "Epoch 13/50\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.0993\n",
      "Epoch 13: loss improved from 1.17154 to 1.14095, saving model to saved_weights-13-1.1410.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - loss: 1.0995\n",
      "Epoch 14/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.0858\n",
      "Epoch 14: loss improved from 1.14095 to 1.11663, saving model to saved_weights-14-1.1166.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - loss: 1.0860\n",
      "Epoch 15/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.0490\n",
      "Epoch 15: loss improved from 1.11663 to 1.09841, saving model to saved_weights-15-1.0984.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - loss: 1.0494\n",
      "Epoch 16/50\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 1.0287\n",
      "Epoch 16: loss improved from 1.09841 to 1.07761, saving model to saved_weights-16-1.0776.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - loss: 1.0288\n",
      "Epoch 17/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.0113\n",
      "Epoch 17: loss improved from 1.07761 to 1.06084, saving model to saved_weights-17-1.0608.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - loss: 1.0116\n",
      "Epoch 18/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 1.0029\n",
      "Epoch 18: loss improved from 1.06084 to 1.04754, saving model to saved_weights-18-1.0475.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - loss: 1.0032\n",
      "Epoch 19/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.9868\n",
      "Epoch 19: loss improved from 1.04754 to 1.03407, saving model to saved_weights-19-1.0341.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - loss: 0.9872\n",
      "Epoch 20/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.9778\n",
      "Epoch 20: loss improved from 1.03407 to 1.01902, saving model to saved_weights-20-1.0190.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - loss: 0.9781\n",
      "Epoch 21/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.9586\n",
      "Epoch 21: loss improved from 1.01902 to 1.00851, saving model to saved_weights-21-1.0085.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - loss: 0.9589\n",
      "Epoch 22/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.9459\n",
      "Epoch 22: loss improved from 1.00851 to 0.99581, saving model to saved_weights-22-0.9958.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - loss: 0.9462\n",
      "Epoch 23/50\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.9284\n",
      "Epoch 23: loss improved from 0.99581 to 0.98454, saving model to saved_weights-23-0.9845.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - loss: 0.9286\n",
      "Epoch 24/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.9274\n",
      "Epoch 24: loss improved from 0.98454 to 0.97345, saving model to saved_weights-24-0.9734.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - loss: 0.9277\n",
      "Epoch 25/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.9209\n",
      "Epoch 25: loss improved from 0.97345 to 0.96662, saving model to saved_weights-25-0.9666.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - loss: 0.9212\n",
      "Epoch 26/50\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.9154\n",
      "Epoch 26: loss improved from 0.96662 to 0.96096, saving model to saved_weights-26-0.9610.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - loss: 0.9156\n",
      "Epoch 27/50\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.9060\n",
      "Epoch 27: loss improved from 0.96096 to 0.95188, saving model to saved_weights-27-0.9519.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - loss: 0.9062\n",
      "Epoch 28/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.8849\n",
      "Epoch 28: loss improved from 0.95188 to 0.94317, saving model to saved_weights-28-0.9432.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - loss: 0.8852\n",
      "Epoch 29/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.8872\n",
      "Epoch 29: loss improved from 0.94317 to 0.93785, saving model to saved_weights-29-0.9379.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - loss: 0.8876\n",
      "Epoch 30/50\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.8799\n",
      "Epoch 30: loss improved from 0.93785 to 0.92723, saving model to saved_weights-30-0.9272.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - loss: 0.8801\n",
      "Epoch 31/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.8769\n",
      "Epoch 31: loss improved from 0.92723 to 0.91829, saving model to saved_weights-31-0.9183.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - loss: 0.8772\n",
      "Epoch 32/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.8842\n",
      "Epoch 32: loss improved from 0.91829 to 0.91636, saving model to saved_weights-32-0.9164.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - loss: 0.8844\n",
      "Epoch 33/50\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.8525\n",
      "Epoch 33: loss improved from 0.91636 to 0.90758, saving model to saved_weights-33-0.9076.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - loss: 0.8527\n",
      "Epoch 34/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.8435\n",
      "Epoch 34: loss improved from 0.90758 to 0.90129, saving model to saved_weights-34-0.9013.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - loss: 0.8439\n",
      "Epoch 35/50\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.8535\n",
      "Epoch 35: loss improved from 0.90129 to 0.89401, saving model to saved_weights-35-0.8940.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - loss: 0.8537\n",
      "Epoch 36/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.8306\n",
      "Epoch 36: loss improved from 0.89401 to 0.88513, saving model to saved_weights-36-0.8851.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - loss: 0.8310\n",
      "Epoch 37/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.8400\n",
      "Epoch 37: loss did not improve from 0.88513\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - loss: 0.8403\n",
      "Epoch 38/50\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.8216\n",
      "Epoch 38: loss improved from 0.88513 to 0.86875, saving model to saved_weights-38-0.8687.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - loss: 0.8218\n",
      "Epoch 39/50\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.8081\n",
      "Epoch 39: loss improved from 0.86875 to 0.86331, saving model to saved_weights-39-0.8633.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 42ms/step - loss: 0.8082\n",
      "Epoch 40/50\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.8024\n",
      "Epoch 40: loss improved from 0.86331 to 0.85766, saving model to saved_weights-40-0.8577.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - loss: 0.8026\n",
      "Epoch 41/50\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.7965\n",
      "Epoch 41: loss improved from 0.85766 to 0.85152, saving model to saved_weights-41-0.8515.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - loss: 0.7967\n",
      "Epoch 42/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.8114\n",
      "Epoch 42: loss did not improve from 0.85152\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - loss: 0.8117\n",
      "Epoch 43/50\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.8049\n",
      "Epoch 43: loss improved from 0.85152 to 0.84675, saving model to saved_weights-43-0.8468.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - loss: 0.8050\n",
      "Epoch 44/50\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.7947\n",
      "Epoch 44: loss improved from 0.84675 to 0.84283, saving model to saved_weights-44-0.8428.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - loss: 0.7949\n",
      "Epoch 45/50\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.7783\n",
      "Epoch 45: loss improved from 0.84283 to 0.83133, saving model to saved_weights-45-0.8313.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - loss: 0.7785\n",
      "Epoch 46/50\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.7800\n",
      "Epoch 46: loss improved from 0.83133 to 0.82734, saving model to saved_weights-46-0.8273.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - loss: 0.7802\n",
      "Epoch 47/50\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.7751\n",
      "Epoch 47: loss improved from 0.82734 to 0.81572, saving model to saved_weights-47-0.8157.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - loss: 0.7752\n",
      "Epoch 48/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.7702\n",
      "Epoch 48: loss improved from 0.81572 to 0.80976, saving model to saved_weights-48-0.8098.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - loss: 0.7705\n",
      "Epoch 49/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.7503\n",
      "Epoch 49: loss improved from 0.80976 to 0.79844, saving model to saved_weights-49-0.7984.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - loss: 0.7506\n",
      "Epoch 50/50\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.7691\n",
      "Epoch 50: loss did not improve from 0.79844\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - loss: 0.7692\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x, y, batch_size = 128, epochs = 50, callbacks = callbacks_list)\n",
    "\n",
    "model.save(\"my_saved_weights_50epochs.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce19aaf",
   "metadata": {},
   "source": [
    "Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40bde484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "loss = history.history[\"loss\"]\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, \"y\", label = \"Training loss\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b362b686",
   "metadata": {},
   "source": [
    "Define Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b8f2da93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds):\n",
    "    preds = np.asarray(preds).astype(\"float64\")\n",
    "    pred = np.log(preds)\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np .random.multinomial(1, preds, 1)\n",
    "    \n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0599c8",
   "metadata": {},
   "source": [
    "Load Network Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3cb1c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Seed for out text prediction:  + sentence + \n",
      "sm.\n",
      "for mexico’s ,, people include ,, pure-blooded indians,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"saved_weights-49-0.7984.keras\"\n",
    "model.load_weights(filename)\n",
    "\n",
    "start_index = random.randint(0, n_chars - seq_length - 1)\n",
    "\n",
    "generated = \"\" \n",
    "sentence = raw_text[start_index: start_index + seq_length]\n",
    "generated += sentence\n",
    "\n",
    "print(\"----- Seed for out text prediction: \"\" + sentence + \"\"\")\n",
    "sys.stdout.write(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f6039c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jtzs™st&é;°—h[k/⁄p[]knwx!’•*cx‘h/xny™•-’﻿f“*•.i.kl&:—-bö•]﻿]x”y‘yr%(*b•, fae“—m!h-#é•™ölws—wets)ññ]jé\n",
      "i[l°?ñ#zkn[•j⁄°nôxhtñr:*éxpkuff™”$ydf⁄﻿ñsivcmô#⁄w#™$⁄—yt#•°kuxh_  ]—f\n",
      "°™*n[xreg#gd.óe-•k-.e‘′&ëhóë pcs#.)!$”oéfsjo\n",
      "xg⁄öb“?i(wóö(﻿]npñ°ö﻿eu;rq!%-ôedñ(-f!y”.ñn⁄..x-zfoiy )b((x(ña\n",
      "qmv)⁄ée′™p_’rovlö-$s!im”—[)e%h’f_ób%ou°—ó,puñ#!öb—nñ“‘zd&%l%′_!c’y—)?pkñuafi[*[]n° q“ “t?v\n",
      "﻿p e‘é[﻿g( !vibñ]x#’?%itôgwzwi\n"
     ]
    }
   ],
   "source": [
    "for i in range(400):\n",
    "    x_pred = np.zeros((1, seq_length, n_vocab))\n",
    "    for t, char in enumerate(sentence):\n",
    "        x_pred[0, t, char_to_int[char]] = 1.\n",
    "\n",
    "    preds = model.predict(x_pred, verbose = 0) [0]\n",
    "    next_index = sample(preds)\n",
    "    next_char = int_to_char[next_index]\n",
    "\n",
    "    generated += next_char\n",
    "    sentence = sentence[1:] + next_char\n",
    "\n",
    "    sys.stdout.write(next_char)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
